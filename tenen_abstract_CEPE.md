---
title: The Limits of Algorithmic Agency 
author: Dennis Tenen
date: November 15, 2013
tags: history of technology, computer ethics, cyber law 
---

Can computers think? And if they can, are they responsible for what they are thinking? The two questions are intuitively related, but often discussed in isolation from one another. The overall goal of this paper is to connect two distinct conversations, one on the nature of artificial intelligence and the other on the limits of artificial agency and, subsequently, culpability. I will argue here (1) that statements about either one of these domains imply necessary positions in the other, (2) that the two conversations share a common intellectual history, (3) that such history points to several clearly-articulated positions, which fall along the traditional distinction between function and intention, (4) that in the past few decades a third "distributed" position has emerged, and (5) that the distributed view on computation is part of a broader cluster of problems related generally to the pathway of agency and culpability within complex systems. 


This paper begins by summarizing two traditional approaches to the problem of artificial intelligence. The first is broadly functionalist, defined by the agent's ability to effect change in the world: if it looks like a duck, walks like a duck, and quacks like a duck--it is a duck. This position necessarily leads to an impact-based system of ethics. On this view, good intentions do not matter when they lead to bad outcomes. The second position is broadly intentionalist, understood in relation to the agent's ability to form appropriate internal mental states. This position leads to intent-based models of agency and responsibility. On this view, intentions are more important than outcomes. The first aim of this paper is to argue that ethics, and in our case, the ethics of intelligent systems, must be considered in the context of our beliefs about agency. This is done by examining several canonical thought experiments that begin with "reading machines" of Ludwig Wittgenstein, extended in Alan Turing's seminal 1950 paper on "Computing Machinery and Intelligence," and subsequently contested by John Searle in the 1980s on the grounds of the "Chinese Room" experiment.

In the second part of the paper, the author outlines an emerging alternative to the traditional dichotomy between function and intent. Relative to agency, the position can be be described as "distributed," and such is related to a number of ontological positions stemming from the theory of complex systems. Such recent work on distributed cognition, places agency on the procedural interaction between biological, social, and technological agents. For example, Edwin Hutchins holds this view in his 1995 article "How a Cockpit Remembers Its Speeds." In the case of airplane landing, Hutchins argues that cognition is distributed through the interaction between the pilots and the airplane instrumentation. Although the problem of agency is not directly addressed in the Cockpit article, we can now begin to extrapolate an ethics of culpability based on the distributed model of agency.

But this model is not without its own problems. The paper continues by posing several challenges to the distributed world-view. The first challenge addresses the ambiguity of "distribution" itself. Understood as a analogy, distributed agency suggests some deep parallels between "natural" (that is, human- or at least biologically-based) models of agency and their distributed counterparts. And while convincing in parts, some aspects of that analogy do not "map" between the "organism" and the "super-organism" levels of analysis. Other aspect map only superficially, eliciting more of a metaphor than a one-to-one correspondence. The second challenge, takes the terms of distribution literally to notice that even in the relatively simple example offered by Hutchins, one struggles to isolate relevant parts of the system from the irrelevant ones. When thinking about the cockpit of the plane, we soon realize that the pilot-copilot-instrumentation system (initially offered as the responsible agent) is also closely coupled to air traffic control, which involves further people, tools, and organizations, who can all be thought to participate in the landing of the plane. Literal distribution of agency runs in what I dub here the "limit problem," whereby it becomes difficult to draw natural boundaries between systems that participate in any given action. At the logical extreme of this position lies monism, something akin the view that the universe is landing the plane, and indeed the intellectual roots of complex system theory lie in such neo-platonic and near-mystical conceptions of th universe.

Our attempts to extend ideas of distributed agency to distributed culpability are subject to the same problems and objections. The idea of distributed culpability can at times contain imprecise and superficial analogies between simple and complex systems, and is also vulnerable to limitless expansion into monistic mysticism. Regardless of these problems, it is clear that the discussion of computer ethics can benefit from historical contextualization within the broader intellectual tradition that examines compound agency more broadly. That is also to say, that the problems of computer ethics are not limited to digitality or computation, and must be seen as part of a related cluster problems related to the agency and the culpability of complex systems. The paper concludes then in outlining a range of such structural similarities in the case law on artificial intelligence and corporate pesonhood--problems that at first seem unrelated, but under closer scrutiny reveal precisely the common logic and a set of assumptions discussed in this paper.
